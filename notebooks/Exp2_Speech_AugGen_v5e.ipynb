{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOWUJFF/OO9iAYdchGSv77z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q librosa soundfile transformers torch accelerate scikit-learn matplotlib seaborn tqdm\n","\n","import os\n","import shutil\n","import glob\n","from pathlib import Path\n","from concurrent.futures import ThreadPoolExecutor\n","\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.auto import tqdm\n","\n","# PyTorch & Transformers\n","import torch\n","from transformers import Wav2Vec2Processor, Wav2Vec2Model\n","\n","# Scikit-Learn\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","# TensorFlow / Keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n"],"metadata":{"id":"dig7xeLb7Tqx","executionInfo":{"status":"ok","timestamp":1765517143752,"user_tz":360,"elapsed":4672,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"0KIuvJa8yS0p","executionInfo":{"status":"error","timestamp":1765517143935,"user_tz":360,"elapsed":175,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}},"outputId":"b2d663ce-e75f-45c0-a07b-a8a9cebd7e45"},"execution_count":18,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Copy zip files\n","shutil.copy(\"/content/drive/MyDrive/RAV_Speech_Archive.zip\", \"/content/RAV_Speech.zip\")\n","shutil.copy(\"/content/drive/MyDrive/RAV_Song_Archive.zip\", \"/content/RAV_Song.zip\")\n","\n","# Unzip locally\n","shutil.unpack_archive(\"/content/RAV_Speech.zip\", \"/content/RAV_Speech\")\n","shutil.unpack_archive(\"/content/RAV_Song.zip\", \"/content/RAV_Song\")\n","\n","print(\"Dataset is ready!\")"],"metadata":{"id":"1xnie9o38NbK","executionInfo":{"status":"aborted","timestamp":1765517144006,"user_tz":360,"elapsed":1,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define all data in a list\n","data_sources = [\n","    \"/content/RAV_Speech\",\n","    \"/content/RAV_Song\"\n","]\n","\n","phrase_map = {1: \"Kids are talking by the door\", 2: \"Dogs are sitting by the door\"}\n","\n","emotion_map = {\n","    1: 'neutral', 2: 'neutral', 3: 'happy', 4: 'sad',\n","    5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'\n","}\n","\n","type_map = {1: 'speech', 2: 'song'}\n","\n","processed_data = []\n","\n","# PROCESSING LOOP\n","for directory in data_sources:\n","    # Search recursively in all directories\n","    file_paths = glob.glob(os.path.join(directory, 'Actor_*', '*.wav'))\n","\n","    for file_path in file_paths:\n","        filename = os.path.basename(file_path)\n","        parts = filename.split('.')[0].split('-')\n","\n","        # RAVDESS filenames have 7 parts\n","        if len(parts) != 7:\n","            continue\n","\n","        # Extract Features\n","        # Filename structure: 02-01-06-01-02-01-12.wav\n","        vocal_channel = int(parts[1]) # Song vs Speech\n","        emotion_code = int(parts[2])\n","        phrase_code = int(parts[4])\n","        actor_code = int(parts[6])\n","\n","        emotion = emotion_map.get(emotion_code, 'unknown')\n","        phrase = phrase_map.get(phrase_code, 'unknown')\n","        data_type = type_map.get(vocal_channel, 'unknown')\n","\n","        # Gender logic: Odd = Male, Even = Female\n","        gender = \"female\" if actor_code % 2 == 0 else \"male\"\n","\n","        # Build Dictionary\n","        processed_data.append({\n","            # combined label\n","            'labels': f\"{gender}_{emotion}\",\n","\n","            # distinct features\n","            'gender': gender,\n","            'emotion': emotion,\n","            'type': data_type,      # track 'speech' vs 'song'\n","            'phrase': phrase,\n","            'actor_id': actor_code, # for splitting Train/Test (to avoid data leakage)\n","            'path': file_path\n","        })\n","\n","# DATAFRAME CREATION\n","RAV_df = pd.DataFrame(processed_data)\n","\n","# VERIFICATION\n","print(f\"Total files processed: {len(RAV_df)}\")\n","print(\"\\n--- Breakdown by Type and Gender ---\")\n","print(RAV_df.groupby(['type', 'gender']).size())\n","print(\"\\n--- Breakdown by Emotion ---\")\n","print(RAV_df.groupby(['emotion']).size())"],"metadata":{"id":"HjXPcOKKO5vm","executionInfo":{"status":"aborted","timestamp":1765517144007,"user_tz":360,"elapsed":5132,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["RAV_df.head()"],"metadata":{"id":"CjrjwPZ6Sex3","executionInfo":{"status":"aborted","timestamp":1765517144008,"user_tz":360,"elapsed":5130,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Data Preparation & Feature Extraction\n","\n","# CONFIGURATION\n","INCLUDE_TYPES = ['speech']\n","#INCLUDE_TYPES = ['speech', 'song']\n","\n","# Filter Data\n","df_active = RAV_df[RAV_df['type'].isin(INCLUDE_TYPES)].copy()\n","df_active['emotion'] = df_active['emotion'].replace('calm', 'neutral')\n","df_active['labels'] = df_active['gender'] + '_' + df_active['emotion']\n","\n","# Ensure actor_id exists\n","if 'actor_id' not in df_active.columns:\n","    df_active['actor_id'] = df_active['path'].apply(lambda x: int(x.split('-')[-1].split('.')[0]))\n","\n","print(f\"Total samples: {len(df_active)}\")\n","\n","# HELPER FUNCTIONS\n","def get_features(y, sr):\n","    try:\n","        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n","        mfcc_delta = librosa.feature.delta(mfcc)\n","        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n","        combined = np.vstack((mfcc, mfcc_delta, mfcc_delta2))\n","        if combined.shape[1] < 150:\n","            pad = 150 - combined.shape[1]\n","            combined = np.pad(combined, ((0, 0), (0, pad)), mode='constant')\n","        else:\n","            combined = combined[:, :150]\n","        return combined.T\n","    except: return None\n","\n","def process_subset(df, augment=False):\n","    X_seq, X_stat, y_out = [], [], []\n","    for path, label in zip(df['path'], df['labels']):\n","        try:\n","            y, sr = librosa.load(path, sr=22050, duration=3)\n","            versions = [y]\n","            if augment:\n","                noise = 0.005 * np.random.uniform() * np.amax(y)\n","                versions.append(y + noise * np.random.normal(size=y.shape[0]))\n","                rate = np.random.uniform(0.9, 1.1)\n","                y_s = librosa.effects.time_stretch(y=y, rate=rate)\n","                if len(y_s) > len(y): y_s = y_s[:len(y)]\n","                else: y_s = np.pad(y_s, (0, len(y)-len(y_s)))\n","                versions.append(y_s)\n","            for v in versions:\n","                feat = get_features(v, sr)\n","                if feat is not None:\n","                    X_seq.append(feat)\n","                    stats = np.concatenate([np.mean(feat,0), np.std(feat,0), np.amax(feat,0), np.amin(feat,0)])\n","                    X_stat.append(stats)\n","                    y_out.append(label)\n","        except: pass\n","    return np.array(X_seq), np.array(X_stat), np.array(y_out)\n","\n","# EXECUTION\n","master_data = {}\n","\n","for g in ['male', 'female']:\n","\n","    subset = df_active[df_active['gender'] == g].copy()\n","\n","    # Split\n","    train = subset[subset['actor_id'] <= 18]\n","    val   = subset[subset['actor_id'].isin([19, 20])]\n","    test  = subset[subset['actor_id'] >= 21]\n","\n","    # Extract\n","    X_train_seq, X_train_stat, y_train = process_subset(train, augment=True)\n","    X_val_seq,   X_val_stat,   y_val   = process_subset(val,   augment=False)\n","    X_test_seq,  X_test_stat,  y_test  = process_subset(test,  augment=False)\n","\n","    # Encode Labels\n","    lb = LabelEncoder()\n","    all_labels = np.concatenate([y_train, y_val, y_test])\n","    lb.fit(all_labels)\n","\n","    # Scale Data\n","    scaler = StandardScaler()\n","    X_train_s = scaler.fit_transform(X_train_stat)\n","\n","    # STORE EVERYTHING (Including Encoder & Scaler)\n","    master_data[g] = {\n","        'X_train_seq': X_train_seq, 'X_train_stat': X_train_s, 'y_train': lb.transform(y_train),\n","        'X_val_seq':   X_val_seq,   'X_val_stat':   scaler.transform(X_val_stat),   'y_val':   lb.transform(y_val),\n","        'X_test_seq':  X_test_seq,  'X_test_stat':  scaler.transform(X_test_stat),  'y_test':  lb.transform(y_test),\n","        'classes': lb.classes_,\n","        'scaler': scaler,  #\n","        'encoder': lb      #\n","    }\n","\n","print(\"\\n Data Ready.\")"],"metadata":{"id":"4Mau16d3A1fR","executionInfo":{"status":"aborted","timestamp":1765517144009,"user_tz":360,"elapsed":5129,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Train Gender Classifier\n","\n","# Prepare Data\n","X_gate_train = np.vstack([master_data['male']['X_train_stat'], master_data['female']['X_train_stat']])\n","# Labels: 1 for Male, 0 for Female\n","y_gate_train = np.concatenate([np.ones(len(master_data['male']['y_train'])), np.zeros(len(master_data['female']['y_train']))])\n","\n","# Train the Random Forest\n","gatekeeper = RandomForestClassifier(n_estimators=100, random_state=42)\n","gatekeeper.fit(X_gate_train, y_gate_train)\n","\n","# Verify\n","X_gate_test = np.vstack([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']])\n","y_gate_test = np.concatenate([np.ones(len(master_data['male']['y_test'])), np.zeros(len(master_data['female']['y_test']))])\n","acc = accuracy_score(y_gate_test, gatekeeper.predict(X_gate_test))\n","\n","print(f\"Classifier Trained. Gender Detection Accuracy: {acc:.2%}\")"],"metadata":{"id":"AjXgJ_1Li51a","executionInfo":{"status":"aborted","timestamp":1765517144009,"user_tz":360,"elapsed":5126,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Model Baseline (Mode)\n","\n","# Statistical Baseline: emotion that appears most often in training\n","\n","m_male = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n","m_male.fit(master_data['male']['X_train_stat'], master_data['male']['y_train'])\n","\n","m_female = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n","m_female.fit(master_data['female']['X_train_stat'], master_data['female']['y_train'])\n","\n","# BLIND EVALUATION\n","\n","#  Blind Test Set\n","X_test = np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']])\n","y_true = np.concatenate([master_data['male']['y_test'], master_data['female']['y_test']])\n","\n","# Gatekeeper Routing\n","gender_preds = gatekeeper.predict(X_test)\n","\n","# Prediction Loop\n","final_preds = []\n","for i in range(len(X_test)):\n","    sample = X_test[i].reshape(1, -1)\n","    model = m_male if gender_preds[i] == 1 else m_female\n","    final_preds.append(model.predict(sample)[0])\n","\n","# RESULTS\n","acc = accuracy_score(y_true, final_preds)\n","print(f\"Baseline Accuracy: {acc:.2%}\")"],"metadata":{"id":"aIBwk0avu6OS","executionInfo":{"status":"aborted","timestamp":1765517144010,"user_tz":360,"elapsed":5125,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Simple ML (Random Forest)\n","\n","# TRAIN MODEL\n","rf_male = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_male.fit(master_data['male']['X_train_stat'], master_data['male']['y_train'])\n","\n","rf_female = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_female.fit(master_data['female']['X_train_stat'], master_data['female']['y_train'])\n","\n","# BLIND EVALUATION\n","\n","# Construct Blind Test Set (Stats)\n","X_test = np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']])\n","y_true = np.concatenate([master_data['male']['y_test'], master_data['female']['y_test']])\n","\n","# Gatekeeper Routing\n","gender_preds = gatekeeper.predict(X_test)\n","\n","# Prediction Loop\n","final_preds = []\n","for i in range(len(X_test)):\n","    sample = X_test[i].reshape(1, -1)\n","    model = rf_male if gender_preds[i] == 1 else rf_female\n","    final_preds.append(model.predict(sample)[0])\n","\n","# RESULTS\n","acc_rf = accuracy_score(y_true, final_preds)  #\n","print(f\"Random Forest Accuracy: {acc_rf:.2%}\")\n","\n","plt.figure(figsize=(5, 4))\n","sns.heatmap(confusion_matrix(y_true, final_preds), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Random Forest Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"7GWcMvhByedX","executionInfo":{"status":"aborted","timestamp":1765517144011,"user_tz":360,"elapsed":5124,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title CNN\n","\n","#  Architecture\n","def create_cnn(input_shape, num_classes):\n","    model = Sequential([\n","        Conv1D(64, 3, activation='relu', input_shape=input_shape),\n","        MaxPooling1D(2),\n","        BatchNormalization(),\n","        Conv1D(128, 3, activation='relu'),\n","        MaxPooling1D(2),\n","        Flatten(),\n","        Dense(64, activation='relu'),\n","        Dropout(0.3),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# TRAIN MODEL\n","\n","# Get shapes from data\n","input_shape = master_data['male']['X_train_seq'].shape[1:]\n","num_classes = len(master_data['male']['classes'])\n","\n","cnn_male = create_cnn(input_shape, num_classes)\n","cnn_male.fit(master_data['male']['X_train_seq'], master_data['male']['y_train'], epochs=15, verbose=0)\n","\n","cnn_female = create_cnn(input_shape, num_classes)\n","cnn_female.fit(master_data['female']['X_train_seq'], master_data['female']['y_train'], epochs=15, verbose=0)\n","\n","# BLIND EVALUATION\n","\n","# A. Construct Blind Test Set (SEQUENCE DATA)\n","X_test_seq = np.concatenate([master_data['male']['X_test_seq'], master_data['female']['X_test_seq']])\n","# We still need STATS for the Gatekeeper!\n","X_test_stat = np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']])\n","y_true = np.concatenate([master_data['male']['y_test'], master_data['female']['y_test']])\n","\n","# Gatekeeper Routing\n","gender_preds = gatekeeper.predict(X_test_stat)\n","\n","# Prediction Loop\n","final_preds = []\n","for i in range(len(X_test_seq)):\n","    # Reshape for Keras (1, time, feat)\n","    sample = np.expand_dims(X_test_seq[i], axis=0)\n","\n","    model = cnn_male if gender_preds[i] == 1 else cnn_female\n","\n","    # Get prediction (argmax for class index)\n","    pred_probs = model.predict(sample, verbose=0)\n","    final_preds.append(np.argmax(pred_probs))\n","\n","# RESULTS\n","acc_cnn = accuracy_score(y_true, final_preds) # <--- CHANGED THIS NAME\n","print(f\"CNN Accuracy: {acc_cnn:.2%}\")\n","\n","plt.figure(figsize=(5, 4))\n","sns.heatmap(confusion_matrix(y_true, final_preds), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"CNN Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"G8UF8pN6ypoT","executionInfo":{"status":"aborted","timestamp":1765517144012,"user_tz":360,"elapsed":5122,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title VGG (Deep 1D CNN)\n","\n","def create_vgg_style(input_shape, num_classes):\n","    model = Sequential([\n","        # Block 1\n","        Conv1D(32, 3, activation='relu', padding='same', input_shape=input_shape),\n","        Conv1D(32, 3, activation='relu', padding='same'),\n","        MaxPooling1D(2),\n","        # Block 2\n","        Conv1D(64, 3, activation='relu', padding='same'),\n","        Conv1D(64, 3, activation='relu', padding='same'),\n","        MaxPooling1D(2),\n","        # Block 3\n","        Conv1D(128, 3, activation='relu', padding='same'),\n","        MaxPooling1D(2),\n","\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.4),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# TRAIN MODEL - Training Male & Female VGG Models\n","input_shape = master_data['male']['X_train_seq'].shape[1:]\n","num_classes = len(master_data['male']['classes'])\n","\n","vgg_male = create_vgg_style(input_shape, num_classes)\n","vgg_male.fit(master_data['male']['X_train_seq'], master_data['male']['y_train'], epochs=15, verbose=0)\n","\n","vgg_female = create_vgg_style(input_shape, num_classes)\n","vgg_female.fit(master_data['female']['X_train_seq'], master_data['female']['y_train'], epochs=15, verbose=0)\n","\n","# BLIND EVALUATION\n","print(\"Running Blind Evaluation...\")\n","\n","# Data Prep\n","X_test_seq = np.concatenate([master_data['male']['X_test_seq'], master_data['female']['X_test_seq']])\n","X_test_stat = np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']])\n","y_true = np.concatenate([master_data['male']['y_test'], master_data['female']['y_test']])\n","\n","# Gatekeeper Routing (Needs Stats)\n","gender_preds = gatekeeper.predict(X_test_stat)\n","\n","# Prediction Loop (Needs Seq)\n","final_preds = []\n","for i in range(len(X_test_seq)):\n","    sample = np.expand_dims(X_test_seq[i], axis=0)\n","    model = vgg_male if gender_preds[i] == 1 else vgg_female\n","    final_preds.append(np.argmax(model.predict(sample, verbose=0)))\n","\n","# RESULTS\n","acc_vgg = accuracy_score(y_true, final_preds)\n","print(f\"VGG Accuracy: {acc_vgg:.2%}\")\n","\n","plt.figure(figsize=(5, 4))\n","sns.heatmap(confusion_matrix(y_true, final_preds), annot=True, fmt='d', cmap='Blues')\n","plt.title(\"VGG Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"mGH24BgJqws-","executionInfo":{"status":"aborted","timestamp":1765517144013,"user_tz":360,"elapsed":5120,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title SOTA Wav2Vec 2.0\n","\n","# SETUP\n","print(\"Loading Emotion-Tuned Wav2Vec Model...\")\n","model_name = \"audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\"\n","processor = Wav2Vec2Processor.from_pretrained(model_name)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","w2v_model = Wav2Vec2Model.from_pretrained(model_name).to(device)\n","\n","def get_w2v_embedding(path):\n","    try:\n","        y, sr = librosa.load(path, sr=16000, duration=3)\n","        inputs = processor(y, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n","        inputs = {k: v.to(device) for k, v in inputs.items()}\n","        with torch.no_grad():\n","            outputs = w2v_model(**inputs)\n","        return torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()[0]\n","    except: return np.zeros(1024)\n","\n","# EXTRACT EMBEDDINGS\n","w2v_data = {}\n","\n","# specific scaler for Wav2Vec embeddings\n","scaler_w2v = StandardScaler()\n","all_train_embeddings = [] # Temp list to fit the scaler later\n","\n","for g in ['male', 'female']:\n","    w2v_data[g] = {'X_train': [], 'y_train': [], 'X_test': [], 'y_test': []}\n","    subset = df_active[df_active['gender'] == g]\n","\n","    # Extract X (Embeddings)\n","    for path in tqdm(subset[subset['actor_id'] <= 18]['path'], desc=f\"{g} Train\"):\n","        emb = get_w2v_embedding(path)\n","        w2v_data[g]['X_train'].append(emb)\n","        all_train_embeddings.append(emb) # Collect for scaler\n","\n","    for path in tqdm(subset[subset['actor_id'] >= 21]['path'], desc=f\"{g} Test\"):\n","        w2v_data[g]['X_test'].append(get_w2v_embedding(path))\n","\n","    le = master_data[g]['encoder']\n","    w2v_data[g]['y_train'] = le.transform(subset[subset['actor_id'] <= 18]['labels'])\n","    w2v_data[g]['y_test'] = le.transform(subset[subset['actor_id'] >= 21]['labels'])\n","\n","    # Convert to Numpy\n","    w2v_data[g]['X_train'] = np.array(w2v_data[g]['X_train'])\n","    w2v_data[g]['X_test'] = np.array(w2v_data[g]['X_test'])\n","\n","\n","# Fit scaler on ALL training data (Male + Female combined)\n","scaler_w2v.fit(all_train_embeddings)\n","\n","# Apply transform\n","for g in ['male', 'female']:\n","    w2v_data[g]['X_train'] = scaler_w2v.transform(w2v_data[g]['X_train'])\n","    w2v_data[g]['X_test'] = scaler_w2v.transform(w2v_data[g]['X_test'])\n","\n","# TRAIN SVM HEAD\n","svm_male = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n","svm_male.fit(w2v_data['male']['X_train'], w2v_data['male']['y_train'])\n","\n","svm_female = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n","svm_female.fit(w2v_data['female']['X_train'], w2v_data['female']['y_train'])\n","\n","# EVALUATE\n","X_test = np.concatenate([w2v_data['male']['X_test'], w2v_data['female']['X_test']])\n","y_true = np.concatenate([w2v_data['male']['y_test'], w2v_data['female']['y_test']])\n","# Gatekeeper checks stats data\n","gender_preds = gatekeeper.predict(np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']]))\n","\n","final_preds = []\n","for i in range(len(X_test)):\n","    sample = X_test[i].reshape(1, -1)\n","    model = svm_male if gender_preds[i] == 1 else svm_female\n","    final_preds.append(model.predict(sample)[0])\n","\n","acc_w2v_sota = accuracy_score(y_true, final_preds)\n","print(f\"\\n Model H (Wav2Vec+SVM) Accuracy: {acc_w2v_sota:.2%}\")"],"metadata":{"id":"S3XFqRoYCM-i","executionInfo":{"status":"aborted","timestamp":1765517144014,"user_tz":360,"elapsed":5118,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title The Hybrid Ensemble (Wav2Vec + CNN)\n","\n","print(\" Running Hybrid Ensemble Inference\")\n","\n","# Setup Data Pointers\n","# Wav2Vec Data (Scaled)\n","X_w2v = np.concatenate([w2v_data['male']['X_test'], w2v_data['female']['X_test']])\n","# CNN Data (Sequence)\n","X_seq = np.concatenate([master_data['male']['X_test_seq'], master_data['female']['X_test_seq']])\n","# True Labels\n","y_true = np.concatenate([w2v_data['male']['y_test'], w2v_data['female']['y_test']])\n","\n","# Gatekeeper Decision\n","gender_preds = gatekeeper.predict(np.concatenate([master_data['male']['X_test_stat'], master_data['female']['X_test_stat']]))\n","\n","# Inference Loop\n","final_preds_hybrid = []\n","\n","for i in range(len(y_true)):\n","    is_male = gender_preds[i] == 1\n","\n","    # Get Wav2Vec Probability (SVM)\n","    model_svm = svm_male if is_male else svm_female\n","    prob_w2v = model_svm.predict_proba(X_w2v[i].reshape(1, -1))[0]\n","\n","    # Get CNN Probability\n","    model_cnn = cnn_male if is_male else cnn_female # Assumes Cell 4 ran\n","    prob_cnn = model_cnn.predict(np.expand_dims(X_seq[i], axis=0), verbose=0)[0]\n","\n","    # Weighted Mix (0.6 / 0.4)\n","    avg_prob = (prob_w2v * 0.6) + (prob_cnn * 0.4)\n","    final_preds_hybrid.append(np.argmax(avg_prob))\n","\n","# Score\n","acc_hybrid = accuracy_score(y_true, final_preds_hybrid)\n","print(f\"Model I (Hybrid) Accuracy: {acc_hybrid:.2%}\")"],"metadata":{"id":"rTFhfMJy-Bgh","executionInfo":{"status":"aborted","timestamp":1765517144015,"user_tz":360,"elapsed":5117,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Final Results\n","\n","# Scores from previous cells\n","scores = {\n","    'Baseline (Mode)': locals().get('acc', 0),           #\n","    'Random Forest': locals().get('acc_rf', 0),          #\n","    '1D CNN': locals().get('acc_cnn', 0),                #\n","    'VGG Style': locals().get('acc_vgg', 0),             #\n","    'Wav2Vec + SVM': locals().get('acc_w2v_sota', 0),    #\n","    'Hybrid Ensemble': locals().get('acc_hybrid', 0)     #\n","}\n","\n","# Create DataFrame\n","df_results = pd.DataFrame(list(scores.items()), columns=['Model', 'Accuracy'])\n","df_results = df_results.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n","\n","# Identify Winner\n","best_model_name = df_results.iloc[0]['Model']\n","best_acc = df_results.iloc[0]['Accuracy']\n","\n","# Plot\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Accuracy', y='Model', data=df_results, palette='viridis', hue='Model', legend=False)\n","plt.xlim(0, 1.0)\n","\n","# Add text labels\n","for i, v in enumerate(df_results['Accuracy']):\n","    plt.text(v + 0.01, i, f\"{v:.1%}\", va='center', fontweight='bold', fontsize=12)\n","\n","plt.title(f'Experiment 2: Speech (Augmented, Gender)', fontsize=16)\n","#plt.title(f'Final Project Results\\nWinner: {best_model_name}', fontsize=16)\n","\n","plt.grid(axis='x', alpha=0.3)\n","plt.show()\n","\n","print(f\"\\n The Winning Model is: {best_model_name} with {best_acc:.2%} accuracy.\")"],"metadata":{"id":"KNUmvE1i0TTa","executionInfo":{"status":"aborted","timestamp":1765517144015,"user_tz":360,"elapsed":5115,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_results)"],"metadata":{"id":"F5u6KPsV_MQF","executionInfo":{"status":"aborted","timestamp":1765517144016,"user_tz":360,"elapsed":5113,"user":{"displayName":"kris mehra","userId":"01256880938666547278"}}},"execution_count":null,"outputs":[]}]}